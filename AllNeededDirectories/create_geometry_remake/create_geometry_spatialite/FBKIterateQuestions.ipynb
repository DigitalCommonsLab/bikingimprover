{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztVeZe_0jTnJ",
        "outputId": "74a34d24-f63e-4c3f-bdc7-83b3856ed658"
      },
      "outputs": [],
      "source": [
        "#First of all I have to acess my drive in order to retrieve the trento pbf osm or xml file\n",
        "import shutil\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbxaqFxNjWK9",
        "outputId": "dcea7666-1ff6-4e7d-c070-30b6e42ab275"
      },
      "outputs": [],
      "source": [
        "!pip install osmium\n",
        "!pip install --no-binary :all: osmium\n",
        "!pip install PyYAML==5.4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr0GlrkG4tIs"
      },
      "source": [
        "# **Funzionamento del file .yaml**\n",
        "\n",
        "Parte riguardante i campi \"way-keys\":</br>\n",
        "- Campo way-keys è costituito da vari campi key, il campo key è costituito dagli elementi name, values, values_not_to_have, tags, questions, must_have_tag, must_not_have_tag.\n",
        "> - name: Nome della chiave che andremo a cercare (per es. highway)\n",
        "> - values: costituito da diversi campi value, rappresentano i valori che sono associati alla chiave specificata dal campo name. (per es. motorway). Questo valore dovrà essere quindi presente nella chiave\n",
        "> - values_not_to_have: costituito da diversi campim value, rappresentano i valori che non possono essere associati alla chiave specificata dal campo name. (per es. motorway). Se la chiave ha questo valore allora verrà scartata\n",
        "> - tags: costituito da vari campi tag\n",
        ">> - tag: costituito dai campi name, value, question, score, validating e answers. \n",
        ">>> - name: il campo name all'interno del tag rappresenta il tag che abbiamo scelto. Cerchiamo quindi se questo tag è presente nell'elemento selezionato. (per es. bicycle)\n",
        ">>> - value: rappresenta il valore del tag. (per es. \"yes\") \n",
        ">>> - question: rappresente la domanda da effettuare nel caso l'elemento scelto abbia come tag quello indicato con valore indicato.\n",
        ">>> - score: rappresenta il punteggio che viene assegnato al giocatore se risponde.\n",
        ">>> - validating: campo che mostra se la domanda sarà di validazione oppure no.\n",
        ">>> - answers: campo che indica le possibili risposte che lo user può dare alla domanda. Se il campo è none allora è una missione di validazione e le uniche risposte possibili sono sì o no.\n",
        "\n",
        "> - questions: costituito da vari campi question, rappresentano le domande da effettuare per qualunque elemento avente come chiave quella richiesta. \n",
        ">> - question: costituito da campi question, score, tagAnswer e answers.\n",
        ">>> - question: rappresenta la domanda associata\n",
        ">>> - score: rappresenta il punteggio associato se lo user risponde alla domanda.\n",
        ">>> - tagAnswer: rappresenta il tag associato alla risposta.\n",
        ">>> - answers: rappresenta le risposte che lo user può inserire.\n",
        "\n",
        "> - must_have_tag: Costituito da vari campi tag, rappresenta tutti i tag che la nostra chiave deve avere. Contiene inoltre i valori che il tag può o non può avere\n",
        ">> - tag: costituito da campi name, values_to_discard, values_to_have\n",
        ">>> - name: nome del tag (per es. bicycle)\n",
        ">>> - values_to_discard: i valori associati al campo tag che se posseduti fanno scartare l'elemento (per es. \"yes\")\n",
        ">>> - values_to_have: i valori associati al campo tag che devono essere posseduti affinchè l'elemento non venga scartato (per es. \"yes\")\n",
        "> - must_not_have_tag: costituito da vari campi tag, rappresentano i nomi dei tag che se presenti nel nostro elemento lo fanno scartare.\n",
        "\n",
        "Parte riguardante i campo \"node-keys\":</br>\n",
        "- Il campo node-keys è costituito da vari campi key, il campo key è costituito dagli elementi name, values, tags, questions.\n",
        "> - name: nome della chiave che ricerchiamo (per es. amenity)\n",
        "> - values: costituito da vari campi value\n",
        ">> - value: campi aventi un elemento name e uno question\n",
        ">>> - name: costituisce il valore che deve possedere la chaive ricercata (per es. bicycle_parking)\n",
        ">>> - question: La domanda associata nel caso in cui l'elemento fosse presente\n",
        "> - tags: costituito da vari campi tag, rappresentano i tag che l'elemento deve possedere oltre alla chiave\n",
        ">> - tag: costituito dai campi name, value e question\n",
        ">>> - name: il nome del tag ricercato (per es. bicycle)\n",
        ">>> - value: il valore che deve possedere il tag (per es. yes)\n",
        ">>> - question: La domanda associata se il tag è presente\n",
        "> - questions: costituito da vari campi question che indicano le domande da effettuare se la chiave viene trovata. Questo campo viene visualizzato indipendentemente dal valore della chiave. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp_GNnyPjZRR",
        "outputId": "d91bffaf-2ae1-452a-a8c4-cf6d008852ff"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "from yaml.loader import SafeLoader\n",
        "\n",
        "yamlFile=\"tmp/tagAndKeys_NewVersion_Answer.yaml\"\n",
        "trentoFile=\"TrentoFileXml/Trento.xml\"\n",
        "cityDirectory = \"CityDirectory\"\n",
        "cityFiles = [] #just to cycle\n",
        "cityFilesOrder = [] #useful to know which data belong to which city and keep them separated.\n",
        "\n",
        "cityD = os.listdir(cityDirectory)\n",
        "for i in cityD:\n",
        "    cityFiles.append(cityDirectory + \"/\" + i)\n",
        "    cityFilesOrder.append(i.replace('.xml',''))\n",
        "\n",
        "print(cityFiles)\n",
        "\n",
        "#EXAMPLE ON HOW TO USE YAML FILES\n",
        "# Open the file and load the file\n",
        "#once Python exits from the “with” block, the file is automatically closed.\n",
        "with open(yamlFile) as f:\n",
        "    data = yaml.load(f, Loader=SafeLoader)\n",
        "    sorted_data = yaml.dump(data, sort_keys=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Questa parte di Osmium in realtà penso si possa eliminare, TODO PROVARE A ELIMINARE QUESTA SEZIONE E MODIFICARE CODICE IN MODO CHE RIFUNZIONI. MI BASTA ESTRARRE OGNI VIA E NODO ANZICHE' QUELLI CHE HANNO A CHE FARE SOLO CON LE BICICLETTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deP-ATtRs4-p",
        "outputId": "a24e8484-5fc6-4268-aa93-59db605766d8"
      },
      "outputs": [],
      "source": [
        "import osmium\n",
        "!pip install --no-binary :all: osmium\n",
        "\n",
        "#DEVO METTERE HIGHWAY != DA MOTORWAY, MOTORWAY_LINK, motorway_junction, \n",
        "\n",
        "class BicycleHandler(osmium.SimpleHandler):\n",
        "    def __init__(self):\n",
        "        super(BicycleHandler, self).__init__()\n",
        "        self.ways = []\n",
        "        self.nodes = []\n",
        "        nodeKeyName = []\n",
        "        wayKeyName = []\n",
        "\n",
        "    \n",
        "    def node(self, n):\n",
        "        tags = {}\n",
        "        if len(n.tags) > 0:\n",
        "            for tag in n.tags:\n",
        "                tags[tag.k] = tag.v\n",
        "\n",
        "        _node = {\n",
        "                  'id':        n.id,\n",
        "                  'version':   n.version,\n",
        "                  'uid':       n.uid,\n",
        "                  'timestamp': n.timestamp,\n",
        "                  'changeset': n.changeset,\n",
        "                  'tags':      tags,\n",
        "                  'lat':       n.location.lat,\n",
        "                  'lon':       n.location.lon,\n",
        "                }\n",
        "        for k in self.nodeKeyName:\n",
        "          if n.tags.get(k) != \"no\" and n.tags.get(k) is not None:\n",
        "            self.nodes.append(_node)\n",
        "\n",
        "\n",
        "    def way(self, w):\n",
        "      tags = {}\n",
        "      if len(w.tags) > 0:\n",
        "            for tag in w.tags:\n",
        "                tags[tag.k] = tag.v\n",
        "\n",
        "      _way = {\n",
        "                  'id':        w.id,\n",
        "                  'version':   w.version,\n",
        "                  'uid':       w.uid,\n",
        "                  'timestamp': w.timestamp,\n",
        "                  'changeset': w.changeset,\n",
        "                  'tags':      tags,\n",
        "                }\n",
        "      \n",
        "      for k in self.wayKeyName:\n",
        "        if w.tags.get(k) != \"no\" and w.tags.get(k) is not None:\n",
        "          self.ways.append(_way)\n",
        "\n",
        "outWayKeyNames = []\n",
        "outNodeKeyNames = []\n",
        "\n",
        "def elementAlreadyHere(name_way, my_list):\n",
        "  for i in my_list:\n",
        "    if i == name_way:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "with open(yamlFile) as f:\n",
        "    data = yaml.load(f, Loader=SafeLoader)\n",
        "\n",
        "    for keys,value in data['way-keys'].items():\n",
        "        print(data[\"way-keys\"][keys][\"name\"])\n",
        "        #print(\"PRINTING KEYS AND VALUES\")\n",
        "        #print(keys)\n",
        "        #print(value)\n",
        "        print(\"FINISH PRINTING KEYS AND VALUES\")\n",
        "        if data[\"way-keys\"][keys][\"name\"]!=\"None\":\n",
        "          #Prima verifico se è già presente\n",
        "          if elementAlreadyHere(data[\"way-keys\"][keys][\"name\"], outWayKeyNames) == False:\n",
        "            print(\"WEEE\")\n",
        "            outWayKeyNames.append(data[\"way-keys\"][keys][\"name\"])\n",
        "          #outNodeKeyNames.append(data[\"node-keys\"][keys][\"name\"])\n",
        "    for keys,value in data['node-keys'].items():\n",
        "        print(data[\"node-keys\"][keys][\"name\"])\n",
        "        if data['node-keys'][keys]['name']is not None:\n",
        "          #Prima verifico se è già presente\n",
        "          if elementAlreadyHere(data[\"node-keys\"][keys][\"name\"], outNodeKeyNames) == False:\n",
        "            outNodeKeyNames.append(data[\"node-keys\"][keys][\"name\"])\n",
        "\n",
        "allWayKeyNames = []\n",
        "allNodeKeyNames = []\n",
        "\n",
        "for i in cityFiles:\n",
        "  b = BicycleHandler()\n",
        "  b.wayKeyName = outWayKeyNames\n",
        "  b.nodeKeyName = outNodeKeyNames\n",
        "  b.apply_file(i)\n",
        "  #print(\"WAAAAAAA\")\n",
        "  #print(b.ways[0])\n",
        "  allWayKeyNames.append(b.ways)\n",
        "  allNodeKeyNames.append(b.nodes)\n",
        "  print(len(b.ways))\n",
        "  print(len(b.nodes))\n",
        "print(len(allWayKeyNames))\n",
        "print(len(allNodeKeyNames))\n",
        "#Come faccio a capire quali sono di quale città?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(allWayKeyNames[0][1]) #b.ways[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Initialize the csv file with the elements in the list\n",
        "def createFile(filename, myList):\n",
        "  with open(filename, 'w', newline='') as file:\n",
        "    writer = csv.writer(file, delimiter='|')\n",
        "    writer.writerows(myList)\n",
        "    file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zR7pMion1D7P"
      },
      "outputs": [],
      "source": [
        "#add an element to the list\n",
        "def initList(myList, myString):\n",
        "  myList.append(myString)\n",
        "  return myList\n",
        "\n",
        "#Initialize the csv file with the elements in the list\n",
        "def createFile(filename, myList):\n",
        "  with open(filename, 'w', newline='') as file:\n",
        "    writer = csv.writer(file, delimiter='|')\n",
        "    writer.writerows(myList)\n",
        "    file.close()\n",
        "\n",
        "def iterateThroughAllTags():\n",
        "  with open(yamlFile) as f:\n",
        "    data = yaml.load(f, Loader=SafeLoader)\n",
        "    for keys,value in data['way-keys'].items():\n",
        "      new_data = data['way-keys'][keys]['tags'].items()\n",
        "      for k,v in new_data:\n",
        "          for i,j in v.items():\n",
        "            print(j)\n",
        "            \n",
        "#Function to create the quest, in particular it lets you add an element to the list\n",
        "def createQuest(answers,node_or_way, question, id, key, key_value, tag, tag_value, verified, mylist, score, tag_answer, validated, icon):\n",
        "  value = [node_or_way, question, id, key, key_value, tag, tag_value, verified, score,tag_answer, validated,answers, icon];\n",
        "  mylist = initList(mylist, value)\n",
        "  return mylist;\n",
        "\n",
        "#Check wheter or not the element ahve value in the must_not_have_tags field inside the yaml file\n",
        "def checkMustNotHaveTags(must_not, list_element):\n",
        "  for k,v in must_not.items():\n",
        "    if v in list_element['tags'] and v is not None:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def checkMustHaveValues(must_data, list_element):\n",
        "  #Get data from the yaml file\n",
        "  #for keys,value in data['way-keys'].items():\n",
        "      new_data = must_data\n",
        "      #Itero per ottenere i dati del campo muyst_have\n",
        "      for k,v in new_data.items():\n",
        "        tag_values_have = new_data[k]['values_to_have']\n",
        "        tag_name = new_data[k]['name']\n",
        "        tag_discards = new_data[k]['values_to_discard']\n",
        "        #Check that the tag in the must_have_tab field is also in the list element\n",
        "        #if it is then continue, else return false\n",
        "        if tag_name not in list_element['tags'] and tag_name is not None:\n",
        "          return False\n",
        "        #if tag_discard is not None:\n",
        "        #check that for every element inside the field \"values_to_have\" isn't None, if it is None then continue, if it isn't then make some other checks.\n",
        "        checkNumber=0\n",
        "        for i,j in tag_values_have.items():\n",
        "          if j is not None:\n",
        "            #Check if the value is the same as one of the values_to_have field\n",
        "            if j == list_element['tags'][tag_name]:\n",
        "              checkNumber = 1 #this means that I have an element that is equal, so I can go on\n",
        "          else:\n",
        "            checkNumber = 1\n",
        "        if checkNumber == 0:\n",
        "          return False\n",
        "        #Check the tag_discards field, if even only one of this is the same as the element of the list then discard the element\n",
        "        for i,j in tag_discards.items():\n",
        "          if j is not None:\n",
        "            #print(\"NOT NONE\")\n",
        "            if j == list_element['tags'][tag_name]:\n",
        "              return False\n",
        "      return True\n",
        "\n",
        "#Function to check if the element is already in the list\n",
        "def alreadyPresent(question_list, question, id):\n",
        "  for element in question_list:\n",
        "    if element[1] == question and id==element[2]:\n",
        "      #print(\"ALREADY\")\n",
        "      #print(question)\n",
        "      #if(element[0]==\"NODE\"):\n",
        "      #  print(id + \" \" + question)\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "#Function used to check if the element contains the key I'm considering\n",
        "def checkHasMyKey(my_key,i):\n",
        "  if my_key in i['tags']:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "#Function to check if the element doesn't contain certain values in the yaml file\n",
        "def checkValuesNot(my_key,i,values_not_to_have):\n",
        "  for k,v in values_not_to_have.items():\n",
        "    #print(v)\n",
        "    if str(i['tags'][my_key]) == v:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def checkValuesYes(my_key,i,values_to_have):\n",
        "  for k,v in values_to_have.items():\n",
        "    if v == None:\n",
        "      return True\n",
        "    if str(i['tags'][my_key]) == v:\n",
        "      return True\n",
        "  return False;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Create the single files for every node and way mission\n",
        "import os\n",
        "\n",
        "#question_list_sorted = question_list_sorted[:-1]\n",
        "\n",
        "def writeInFile(element_to_write, path):\n",
        "    with open(path, \"a\") as f:\n",
        "        f.write(element_to_write)\n",
        "        f.close()\n",
        "\n",
        "def AddQuestions(my_list, my_node_path, my_way_path):\n",
        "    for i in my_list:\n",
        "        my_id = i[2]\n",
        "        node_or_way = i[0]\n",
        "        #answers = i[11]\n",
        "        if node_or_way == \"NODE\":\n",
        "            #print(\"chimichanga\")\n",
        "            path = my_node_path + \"/\" + str(my_id) + \".csv\"\n",
        "            my_str = ''.join(str(e) + \"|\" for e in i)\n",
        "            writeInFile(my_str,path)\n",
        "            writeInFile(\"\\n\", path)\n",
        "        else:\n",
        "            path = my_way_path + \"/\" +str(my_id) + \".csv\"\n",
        "            my_str = ''.join(str(e) + \"|\" for e in i)\n",
        "            writeInFile(my_str,path)\n",
        "            writeInFile(\"\\n\", path)\n",
        "\n",
        "for i in cityFilesOrder:\n",
        "    nodes_path = \"tmp/nodes_question/\" + i\n",
        "    ways_path = \"tmp/ways_question/\" +i\n",
        "    try:\n",
        "        #os.mkdir(\"tmp/GeojsonFiles/centerWayPoints/\" + i)\n",
        "        os.mkdir(\"tmp/GeojsonFiles/singleWaysFiles/\" + i)\n",
        "        os.mkdir(\"tmp/GeojsonFiles/singleNodesFiles/\" + i)\n",
        "        os.mkdir(\"tmp/GeojsonFiles/Overpass/\" + i)\n",
        "        os.mkdir(\"tmp/XmlFiles/\" + i)\n",
        "        os.mkdir(\"tmp/allQuestions/\" + i)\n",
        "        os.mkdir(nodes_path)\n",
        "        os.mkdir(ways_path)\n",
        "    except OSError:\n",
        "        print(\"creation failed\")\n",
        "    else:\n",
        "        print(\"folders created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOaVayNt9PD6"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "question_list = [[\"NODE OR WAY\", \"QUESTION\", \"ID\", \"KEY\", \"KEY_VALUE\", \"TAG\", \"TAG_VALUE\", \"VERIFIED\",\"SCORE\",\"TAGANSWER\", \"VALIDATING\",\"ANSWERS\",\"ICON\"]]\n",
        "#The tag answer represents the tag or the key that we have to search in the answer\n",
        "\n",
        "#Start with the quest about the \"WAY\"\n",
        "\n",
        "#Open the yaml file to get all the tag that I need\n",
        "#cycle the way list and check the condition of the yaml file in order to initialize the questions.\n",
        "#For every way inside the list verify if I need to create a question or not.\n",
        "\n",
        "def createQuestList(waylistname, nodelistname, question_list):\n",
        "  yamlFile=\"tmp/tagAndKeys_NewVersion_Answer.yaml\"\n",
        "  with open(yamlFile) as f:\n",
        "      data = yaml.load(f, Loader=SafeLoader)\n",
        "      for i in waylistname:\n",
        "        for keys,value in data['way-keys'].items():\n",
        "          new_data = data['way-keys'][keys]['tags']\n",
        "          values_not_to_have = data['way-keys'][keys]['values_not_to_have']\n",
        "          values_to_have = data[\"way-keys\"][keys][\"values\"]\n",
        "          questions_data = data['way-keys'][keys]['questions']\n",
        "          must_data = data['way-keys'][keys]['must_have_tag']\n",
        "          must_not_data = data['way-keys'][keys]['must_not_have_tag']\n",
        "          my_key = data[\"way-keys\"][keys][\"name\"]\n",
        "          #Check that it contains my key\n",
        "          if checkHasMyKey(my_key,i):\n",
        "            #Check that my key doesn't have values contained in the values_not_to_have field inside the yaml file\n",
        "            if checkValuesNot(my_key,i,values_not_to_have):\n",
        "              #Check that my key contains the value inside the values section, if it does then go on. If there aren't value to check then continue\n",
        "              if checkValuesYes(my_key,i,values_to_have):\n",
        "                #check if the element has the must_have_tag\n",
        "                if checkMustHaveValues(must_data, i) and checkMustNotHaveTags(must_not_data, i):\n",
        "                #cycle through all the various tags in the tags section of the yaml file in order to create the questions\n",
        "                  for k,v in new_data.items():\n",
        "                    tag_value = new_data[k]['value']\n",
        "                    tag_name = new_data[k]['name'] #THIS IS ALSO THE TAG THAT I HAVE TO SEARCH IN THE FUTURE.\n",
        "                    tag_question = new_data[k]['question']\n",
        "                    tag_score = new_data[k]['score']\n",
        "                    validate_bool = new_data[k]['validating']\n",
        "                    #print(new_data[k])\n",
        "                    #possible_answers = \"\"\n",
        "                    possible_answers = new_data[k]['answers']\n",
        "                    icon = new_data[k][\"icon\"]\n",
        "                    #If the value is none then I can instantly generate the question\n",
        "                    if tag_value == 'None':\n",
        "                      #Check that in b.ways there's not the attribute tag_name, if there isn't then I can create the question\n",
        "                      if tag_name not in i['tags']:\n",
        "                        #Check if the question is already in the list\n",
        "                        if alreadyPresent(question_list, tag_question, str(i['id'])) == False: \n",
        "                          question_list = createQuest(possible_answers,'WAY', tag_question, str(i['id']), my_key, str(i['tags'][my_key]), tag_name, 'NONE', 'NO', question_list, tag_score, tag_name, validate_bool, icon)\n",
        "                    else:\n",
        "                      #Check whether or not the tag and the value inside the yaml file are also in the element, if they are then add the element to the questions\n",
        "                      if tag_name in i['tags'] and tag_value == str(i['tags'][tag_name]):\n",
        "                        #Check if the questions is already contained in the question list\n",
        "                        if alreadyPresent(question_list, tag_question, str(i['id'])) == False: \n",
        "                          question_list = createQuest(possible_answers,'WAY', tag_question, str(i['id']), my_key, str(i['tags'][my_key]), tag_name, str(i['tags'][tag_name]), 'NO', question_list, tag_score, tag_name, validate_bool,icon)\n",
        "                #Now I can add the question that are in the questions section of the yamls file. This questions do not need any verification process\n",
        "                  for k,v in questions_data.items():\n",
        "                    if v is not None:\n",
        "                      #print(v)\n",
        "                      question_value = questions_data[k]['question']\n",
        "                      score_value = questions_data[k]['score']\n",
        "                      answer_value = questions_data[k]['tagAnswer']\n",
        "                      question_answers = questions_data[k]['answers']\n",
        "                      icon = questions_data[k][\"icon\"]\n",
        "                      #print(question_value)\n",
        "                      #print(score_value)\n",
        "                      if question_value is not None:\n",
        "                        if alreadyPresent(question_list, question_value, str(i['id'])) == False:\n",
        "                          question_list = createQuest(question_answers,\"WAY\", question_value, str(i['id']), my_key, str(i['tags'][my_key]), 'NONE', 'NONE', 'NO', question_list, score_value, answer_value,\"no\",icon)\n",
        "\n",
        "  #Same thing for the node questions\n",
        "  with open(yamlFile) as f:\n",
        "      data = yaml.load(f, Loader=SafeLoader)\n",
        "      for i in nodelistname:\n",
        "        for keys,value in data['node-keys'].items():\n",
        "          new_data = data['node-keys'][keys]['tags']\n",
        "          #print(new_data)\n",
        "          questions_data = data['node-keys'][keys]['questions']\n",
        "          my_key = data[\"node-keys\"][keys][\"name\"]\n",
        "          my_values = data[\"node-keys\"][keys][\"values\"]\n",
        "          if checkHasMyKey(my_key,i):\n",
        "            #Check the values field, my key needs to have the value written in the name field and then I create the mission associated\n",
        "            for k,v in my_values.items():\n",
        "              value_name = my_values[k]['name']\n",
        "              value_question = my_values[k]['question']\n",
        "              value_score = my_values[k]['score']\n",
        "              value_answer = my_values[k]['tagAnswers']\n",
        "              value_validating = my_values[k]['validating']\n",
        "              possible_answers = my_values[k]['answers']\n",
        "              icon = my_values[k]['icon']\n",
        "              #print(possible_answers)\n",
        "              if value_name is not None:\n",
        "                #Create the mission if it contains the value\n",
        "                if value_name == i['tags'][my_key]:\n",
        "                  if alreadyPresent(question_list, value_question, str(i['id'])) == False: \n",
        "                    question_list = createQuest(possible_answers,\"NODE\", value_question, str(i['id']), my_key, str(i['tags'][my_key]),'NONE', 'NONE','NO',question_list, value_score, value_answer, value_validating,icon)\n",
        "\n",
        "            #Cycle through all the various tags in the tags section of the yaml file in order to create the questions\n",
        "            for k,v in new_data.items():\n",
        "              tag_value = new_data[k]['value']\n",
        "              tag_name = new_data[k]['name']\n",
        "              tag_question = new_data[k]['question']\n",
        "              tag_score = new_data[k]['score']\n",
        "              validating_value = new_data[k]['validating']\n",
        "              #print(new_data[k])\n",
        "              tag_answers = new_data[k]['answers']\n",
        "              icon = new_data[k][\"icon\"]\n",
        "              #tag_answer = new_data[\"tagAnswers\"]\n",
        "              #If the value is None then you can create the question\n",
        "              if tag_value == 'None':\n",
        "                #Check that there's no attribute tag_name in the b.ways, if there isn't then create the question\n",
        "                if tag_name not in i['tags']:\n",
        "                  #Check that the questions isn't already in the list\n",
        "                  if alreadyPresent(question_list, tag_question, str(i['id'])) == False: \n",
        "                    question_list = createQuest(tag_answers ,'WAY', tag_question, str(i['id']), my_key, str(i['tags'][my_key]), tag_name, 'NONE', 'NO', question_list, tag_score, tag_name, validating_value,icon)\n",
        "              else:\n",
        "                #Check if the tag and the value in the yaml file are also in the element in the list, if they are then add the element to the questions\n",
        "                if tag_name in i['tags'] and tag_value == str(i['tags'][tag_name]):\n",
        "                  #Check if the way already contains the question I'm creating\n",
        "                  if alreadyPresent(question_list, tag_question, str(i['id'])) == False: \n",
        "                    question_list = createQuest(tag_answers ,'WAY', tag_question, str(i['id']), my_key, str(i['tags'][my_key]), tag_name, str(i['tags'][tag_name]), 'NO', question_list, tag_score, tag_name,validating_value,icon)\n",
        "          \n",
        "            #Now I can add the question that are in the questions section of the yaml file, these don't need any verification\n",
        "            for k,v in questions_data.items():\n",
        "              if v is not None:\n",
        "                question_value = questions_data[k]['question']\n",
        "                score_value = questions_data[k]['score']\n",
        "                question_answers = questions_data[k]['answers']\n",
        "                icon = questions_data[k][\"icon\"]\n",
        "                if question_value is not None:\n",
        "                  if alreadyPresent(question_list, question_value, str(i['id'])) == False:\n",
        "                    question_list = createQuest(question_answers,\"WAY\", question_value, str(i['id']), my_key, str(i['tags'][my_key]), 'NONE', 'NONE', 'NO', question_list, score_value, my_key,\"no\",icon)\n",
        "  return question_list            \n",
        "\n",
        "j=0\n",
        "for i in allWayKeyNames:\n",
        "  nodes_path = \"tmp/nodes_question/\" + cityFilesOrder[j]\n",
        "  ways_path = \"tmp/ways_question/\" + cityFilesOrder[j]\n",
        "  question_list = [[\"NODE OR WAY\", \"QUESTION\", \"ID\", \"KEY\", \"KEY_VALUE\", \"TAG\", \"TAG_VALUE\", \"VERIFIED\",\"SCORE\",\"TAGANSWER\", \"VALIDATING\",\"ANSWERS\",\"ICON\"]]\n",
        "  question_list = createQuestList(i,allNodeKeyNames[j],question_list)\n",
        "  filename = \"tmp/allQuestions/\" + cityFilesOrder[j] + \"/wayQuests.csv\"\n",
        "  not_sorted = \"tmp/allQuestions/\" + cityFilesOrder[j] + \"/wayQuestsNotSorted.csv\"\n",
        "  question_list_sorted = sorted(question_list, key=lambda x:x[2])\n",
        "  question_list_sorted = question_list_sorted[:-1]\n",
        "  createFile(filename, question_list_sorted)\n",
        "  createFile(not_sorted, question_list)\n",
        "  #AddQuestions(question_list_sorted, nodes_path, ways_path)\n",
        "  j=j+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjyZcvaH4-BE",
        "outputId": "b476477e-ddfa-45e1-c226-8d94183e89cc"
      },
      "outputs": [],
      "source": [
        "!pip install overpy\n",
        "!pip install geojson\n",
        "!pip install overpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZotq_z35if7"
      },
      "outputs": [],
      "source": [
        "#Function used to create the query for overpass\n",
        "def createQuery(fileName, node_or_way, node_or_way_title):\n",
        "  myQuery = node_or_way + \"(id:\"\n",
        "  with open(fileName) as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter='|')\n",
        "    line_count = 0\n",
        "    for row in csv_reader:\n",
        "      if line_count == 0:\n",
        "        print(f'Column names are {\", \".join(row)}')\n",
        "        line_count += 1\n",
        "      elif line_count ==1:\n",
        "        if str(f'{row[0]}') == node_or_way_title:\n",
        "          myQuery = myQuery + str(f'{row[2]}');\n",
        "          line_count += 1\n",
        "      else:\n",
        "        if str(f'{row[0]}') == node_or_way_title:\n",
        "          myQuery = myQuery + \",\" + str(f'{row[2]}');\n",
        "          line_count += 1\n",
        "    print(f'Processed {line_count} lines.')\n",
        "  #myQuery = \"[out:json];\" + myQuery + \");(._;>;);out geom;\"\n",
        "  myQuery = myQuery + \");(._;>;);out meta;\"\n",
        "  return myQuery\n",
        "\n",
        "#Function to create the quyery for overpy\n",
        "def createQueryOverpy(fileName, node_or_way, node_or_way_title):\n",
        "  myQuery = node_or_way + \"(id:\"\n",
        "  with open(fileName) as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter='|')\n",
        "    line_count = 0\n",
        "    for row in csv_reader:\n",
        "      if line_count == 0:\n",
        "        print(f'Column names are {\", \".join(row)}')\n",
        "        line_count += 1\n",
        "      elif line_count ==1:\n",
        "        if str(f'{row[0]}') == node_or_way_title:\n",
        "          myQuery = myQuery + str(f'{row[2]}');\n",
        "          line_count += 1\n",
        "      else:\n",
        "        if str(f'{row[0]}') == node_or_way_title:\n",
        "          myQuery = myQuery + \",\" + str(f'{row[2]}');\n",
        "          line_count += 1\n",
        "    print(f'Processed {line_count} lines.')\n",
        "  myQuery = \"[out:json];\" + myQuery + \");(._;>;);out meta;\"\n",
        "  return myQuery\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urcft7mC5ZB8",
        "outputId": "763b68d0-eb6d-417c-f258-c4394066c61f"
      },
      "outputs": [],
      "source": [
        "!pip install geopandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGhJf5ERbC8V",
        "outputId": "a9ce08a4-d198-4665-e4c9-c1e05a1e4dcd"
      },
      "outputs": [],
      "source": [
        "#if this step gives errors it's probably because we have to wait some time between one call and the other. If that's the case then add a counter or something to do so.\n",
        "import requests\n",
        "import overpy\n",
        "import geopandas as gpd\n",
        "\n",
        "xml = []\n",
        "nodeXml = []\n",
        "nodeResult = []\n",
        "api = overpy.Overpass()\n",
        "url = \"https://overpass-api.de/api/interpreter?\"\n",
        "#make the calls to overpass in order to extract the elements that have questions. \n",
        "for i in cityFilesOrder:\n",
        "    file_to_use = \"tmp/allQuestions/\" + i + \"/wayQuestsNotSorted.csv\"\n",
        "    myQuery = createQueryOverpy(file_to_use, \"way\", \"WAY\")\n",
        "    myNodeQuery = createQueryOverpy(file_to_use, \"node\", \"NODE\")\n",
        "    s = myQuery\n",
        "    p = {'data':s}\n",
        "    myNodeBody = {'data':myNodeQuery}\n",
        "    r = requests.post(url,data=p)\n",
        "    nodeResult = requests.post(url, data = myNodeBody)\n",
        "    xml.append(r.text)\n",
        "    nodeXml.append(nodeResult.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AKjNt0ceTfO"
      },
      "outputs": [],
      "source": [
        "#save the answer to some xml files\n",
        "j=0\n",
        "for i in cityFilesOrder:\n",
        "  with open(\"tmp/XmlFiles/\" + i + \"/myXml.xml\", \"w\") as f:\n",
        "    f.write(xml[j])\n",
        "    f.close()\n",
        "  with open(\"tmp/XmlFiles/\" + i + \"/myNodeXml.xml\", \"w\") as f:\n",
        "    f.write(nodeXml[j])\n",
        "    f.close()\n",
        "  j=j+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOfdBGRHdjMk",
        "outputId": "0df30c2e-7ea3-474f-f931-65f6714d48dd"
      },
      "outputs": [],
      "source": [
        "pip install osm2geojson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5yqUeQidoxo"
      },
      "outputs": [],
      "source": [
        "import osm2geojson\n",
        "#convert the files in geojsons and shapes\n",
        "\n",
        "g = []\n",
        "nodeGeo = []\n",
        "for i in cityFilesOrder:\n",
        "    file_to_use = \"tmp/allQuestions/\" + i + \"/wayQuestsNotSorted.csv\"\n",
        "    myQuery = createQueryOverpy(file_to_use, \"way\", \"WAY\")\n",
        "    myNodeQuery = createQueryOverpy(file_to_use, \"node\", \"NODE\")\n",
        "    s = myQuery\n",
        "    g.append(osm2geojson.overpass_call(s))\n",
        "    nodeGeo.append(osm2geojson.overpass_call(myNodeQuery))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euv2xq3GgirM"
      },
      "outputs": [],
      "source": [
        "j=0\n",
        "for i in cityFilesOrder:\n",
        "  with open(\"tmp/GeojsonFiles/Overpass/\" + i + \"/myOverpass_call.geojson\", \"w\") as f:\n",
        "    f.write(g[j])\n",
        "    f.close()\n",
        "    j=j+1\n",
        "\n",
        "j=0\n",
        "for i in cityFilesOrder:\n",
        "  with open(\"tmp/GeojsonFiles/Overpass/\" + i + \"myNodeCall.geojson\", \"w\") as f:\n",
        "    f.write(nodeGeo[j])\n",
        "    f.close()\n",
        "    j=j+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwH4D8UHd2PY",
        "outputId": "511b56c1-cead-40eb-f9de-52a45c7c9fe5"
      },
      "outputs": [],
      "source": [
        "j=0\n",
        "geojson_output = []\n",
        "geojson_node_output = []\n",
        "for i in cityFilesOrder:\n",
        "    geojson_output.append(osm2geojson.json2shapes(g[j]))\n",
        "    geojson_node_output.append(osm2geojson.json2shapes(nodeGeo[j]))\n",
        "    type(geojson_output)\n",
        "    j=j+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMHObjJsiFtC",
        "outputId": "409d16b9-94ab-43fa-9b45-5ca48d73b4c7"
      },
      "outputs": [],
      "source": [
        "geojson_output[0][0]\n",
        "#len(geojson_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-FY_VZ9y8T2",
        "outputId": "ff6d2178-58cc-418d-ad1a-7a9f74046499"
      },
      "outputs": [],
      "source": [
        "geojson_node_output[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Now I want to create a geojson for each single way and node.\n",
        "import json\n",
        "\n",
        "\n",
        "def createGeoJson(outputName, nodeOrWay, folder):\n",
        "    for i in outputName:\n",
        "        my_item = osm2geojson.shape_to_feature(i['shape'], i['properties'])\n",
        "        with open(folder + nodeOrWay + str(i['properties']['id']) + \".geojson\",\"w\") as f:\n",
        "            json.dump(my_item, f)\n",
        "j=0\n",
        "for i in cityFilesOrder:\n",
        "    createGeoJson(geojson_output[j], \"way\", \"tmp/GeojsonFiles/singleWaysFiles/\" + i + \"/\")\n",
        "    createGeoJson(geojson_node_output[j], \"node\", \"tmp/GeojsonFiles/singleNodesFiles/\" + i + \"/\")\n",
        "    j=j+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96B2aCL0kEPg",
        "outputId": "796881a7-564a-4512-9e31-01bc4d684f56"
      },
      "outputs": [],
      "source": [
        "geojson_output[0][0]['properties']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRm_sxAfjMWC"
      },
      "outputs": [],
      "source": [
        "#type(my_object)\n",
        "#create the geodataframes\n",
        "tutto = []\n",
        "node_all = []\n",
        "j=0\n",
        "for i in cityFilesOrder:\n",
        "    tutto.append(gpd.GeoDataFrame(geojson_output[j]))\n",
        "    node_all.append(gpd.GeoDataFrame(geojson_node_output[j]))\n",
        "    j=j+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "F9-ptSOez_pL",
        "outputId": "4b70546e-0bd6-433f-cd8d-17757d3c5a2e"
      },
      "outputs": [],
      "source": [
        "node_all[0].head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEHQ48u8oImF",
        "outputId": "2e8b438f-3421-436d-ead1-4de04b9c9593"
      },
      "outputs": [],
      "source": [
        "#tutto\n",
        "\n",
        "#tutto[1].properties[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqhvbHcvoxn7"
      },
      "outputs": [],
      "source": [
        "j=0\n",
        "for i in cityFilesOrder:\n",
        "    newTutto = tutto[j]\n",
        "    newTutto['way'] = newTutto.properties.apply(lambda x: x['type'])\n",
        "    newTutto['id'] = newTutto.properties.apply(lambda x: x['id'])\n",
        "    tutto[j] = newTutto\n",
        "    newNode = node_all[j]\n",
        "    newNode['node'] = newNode.properties.apply(lambda x: x['type'])\n",
        "    newNode['id'] = newNode.properties.apply(lambda x: x['id'])\n",
        "    node_all[j] = newNode\n",
        "    j = j+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB498n9HqhqG",
        "outputId": "d5c2dd2d-e454-49ae-c0a0-d8bb1aa86c73"
      },
      "outputs": [],
      "source": [
        "#for elements in tutto.properties:\n",
        "  #print(elements)\n",
        "  #print(elements['tags'])\n",
        "  #Uso try except perchè ci sono dei valori che potrebbero non avere la sezione tags.\n",
        "  #try:\n",
        "    #for tag in elements['tags']:\n",
        "      #print(tag)\n",
        "      #tutto[tag] = tutto.properties.apply(lambda x: x['tags'])\n",
        "\n",
        "  #except Exception as e:\n",
        "    #print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gN-6s5Dyokd",
        "outputId": "5a276769-2556-4c33-eda1-76b32e892975"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "node_labels = []\n",
        "\n",
        "j=0\n",
        "for i in cityFilesOrder:\n",
        "  toIter = tutto[j]\n",
        "  for index,row in toIter.iterrows():\n",
        "    #print(index)\n",
        "    try:\n",
        "      node_key = row['properties']['tags'].keys()\n",
        "      chiave = row['properties']['tags'].keys() \n",
        "      for c in chiave:\n",
        "        if c not in labels:\n",
        "          labels.append(c)\n",
        "      for k in node_key:\n",
        "        if k not in node_labels:\n",
        "          node_labels.append(k)\n",
        "    except KeyError as e:\n",
        "      print(e) \n",
        "  j = j+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W9Nr2wkzEuU"
      },
      "outputs": [],
      "source": [
        "def getValue(row, label):\n",
        "  v = \"\"\n",
        "  #print(row)\n",
        "  #row = row['tags']\n",
        "  try:\n",
        "    row = row['tags']\n",
        "    v = row[label]\n",
        "  except KeyError as e:\n",
        "    #print(e)\n",
        "    v = \"\"\n",
        "    pass;\n",
        "  return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "051cDHfI0wRq"
      },
      "outputs": [],
      "source": [
        "j=0\n",
        "for i in cityFilesOrder:\n",
        "  tuttoNew = tutto[j]\n",
        "  nodeNew = node_all[j]\n",
        "  for label in labels:\n",
        "    tuttoNew[label] = tuttoNew.properties.apply(lambda x: getValue(x,label))\n",
        "    tutto[j] = tuttoNew\n",
        "  for label in node_labels:\n",
        "    nodeNew[label] = nodeNew.properties.apply(lambda x: getValue(x,label))\n",
        "    node_all[j] = nodeNew\n",
        "  j=j+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Tmimb_C12sv"
      },
      "outputs": [],
      "source": [
        "j=0\n",
        "for i in cityFilesOrder:\n",
        "    tuttoNew = tutto[j]\n",
        "    tuttoNew['id'] = tuttoNew.properties.apply(lambda x: x['id'])\n",
        "    tuttoNew['type'] = tuttoNew.properties.apply(lambda x: x['type'])\n",
        "    tutto[j] = tuttoNew\n",
        "    nodeNew = node_all[j]\n",
        "    nodeNew['id'] = nodeNew.properties.apply(lambda x: x['id'])\n",
        "    nodeNew['type'] = nodeNew.properties.apply(lambda x: x['type'])\n",
        "    node_all[j] = nodeNew\n",
        "    j=j+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "7x-NT2jM1HmP",
        "outputId": "82ca9192-5c2f-417b-8f04-9c646825cc00"
      },
      "outputs": [],
      "source": [
        "print(tutto[0].head(3))\n",
        "tutto[0]['shape'].head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "95dh3GQ90m-R",
        "outputId": "5568e00d-c364-4d9a-ae1c-6d9cf4f2deaf"
      },
      "outputs": [],
      "source": [
        "node_all[0].head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(type(tutto[0]['shape'].iloc[0]))\n",
        "\n",
        "#this is necessary to find all the centroids\n",
        "print(tutto[0]['shape'].iloc[0].representative_point())\n",
        "gdf_center = []\n",
        "j=0\n",
        "for i in cityFilesOrder:\n",
        "    gdf_c = tutto[j].copy()\n",
        "    my_center_points = []\n",
        "    for k in tutto[j]['shape']:\n",
        "        centerPoint = k.representative_point()\n",
        "        my_center_points.append(centerPoint)\n",
        "    gdf_c = gdf_c.drop(['shape'], axis = 1)\n",
        "    gdf_c['geometry'] = my_center_points #DATAFRAME WITH THE CENTERPOINT, I CAN REMOVE THE SHAPE SINCE I DON'T USE IT ANYMORE\n",
        "    gdf_c.drop(gdf_c.columns.difference(['id','type','geometry','name', 'highway']),1,inplace=True)\n",
        "    gdf_center.append(gdf_c)\n",
        "    j=j+1\n",
        "#gdf_center.head(1)\n",
        "#tutto.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "j=0\n",
        "for i in cityFilesOrder:\n",
        "    tutto[j].drop(tutto[j].columns.difference(['shape','type','id']), 1, inplace=True)\n",
        "    node_all[j].drop(node_all[j].columns.difference(['shape','type','id']), 1, inplace=True)\n",
        "    j=j+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(tutto[0].head(3))\n",
        "node_all[0].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(tutto[0].shape)\n",
        "print(node_all[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#create the geojson with all the centerpoints\n",
        "j=0\n",
        "for i in cityFilesOrder:\n",
        "    my_centerJson = gdf_center[j].to_json()\n",
        "    my_folder = \"tmp/GeojsonFiles/centerWayPoints/\"\n",
        "    with open(my_folder + i + \".geojson\",\"w\") as f:\n",
        "        f.write(my_centerJson)\n",
        "        f.write(\"\\n\")\n",
        "        #json.dump(my_centerJson, f)\n",
        "    j=j+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sqlite3\n",
        "\n",
        "DB_PATH = os.path.join(os.getcwd(), 'database_prova/withvalidation.db')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Create the table with the questions, but before doing so check for existing duplicates\n",
        "import pandas as pd\n",
        "if(os.path.exists('./database_prova/withvalidation.db')):\n",
        "    databaseAlreadyExists = True\n",
        "else:\n",
        "    databaseAlreadyExists = False\n",
        "\n",
        "\n",
        "for i in cityFilesOrder:\n",
        "    my_data = pd.read_csv(\"./tmp/allQuestions/\" + i + \"/wayQuestsNotSorted.csv\", index_col=False, delimiter='|')\n",
        "    my_data = my_data.rename(columns={'NODE OR WAY':'TYPE'})#########\n",
        "    my_data.drop(my_data.columns.difference(['TYPE','QUESTION','ID','SCORE','VALIDATING','ANSWERS','ICON', 'TAGANSWER']), 1, inplace=True)\n",
        "    my_data[\"ANSWER\"] = \"\"\n",
        "    my_data[\"USERANSWERED\"] = \"\"\n",
        "    my_data[\"NUMBEROFVALIDATIONS\"] = 0\n",
        "    my_data[\"USERSWHOVALIDATED\"] = \"\"\n",
        "    print(my_data.head())\n",
        "\n",
        "    with sqlite3.connect(DB_PATH) as conn: \n",
        "        df_sql = my_data.to_sql('question_table_tmp', conn, if_exists='append', index = False)\n",
        "\n",
        "if(databaseAlreadyExists):\n",
        "    query= \"\"\"\n",
        "        SELECT TYPE, QUESTION, ID FROM question_table_tmp \n",
        "        EXCEPT \n",
        "        SELECT TYPE, QUESTION, ID FROM question_table;\n",
        "    \"\"\"\n",
        "else:\n",
        "    query= \"\"\"\n",
        "        SELECT TYPE, QUESTION, ID, SCORE, VALIDATING, ANSWERS, ICON, TAGANSWER, ANSWER, USERANSWERED, NUMBEROFVALIDATIONS, USERSWHOVALIDATED  FROM question_table_tmp \n",
        "    \"\"\"\n",
        "\n",
        "with sqlite3.connect(DB_PATH) as conn: \n",
        "    new_entries = pd.read_sql(query, conn)\n",
        "\n",
        "with sqlite3.connect(DB_PATH) as conn: \n",
        "    df_sql = new_entries.to_sql('question_table', conn, if_exists='append', index = False)\n",
        "\n",
        "\n",
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.enable_load_extension(True)\n",
        "    conn.load_extension(\"mod_spatialite\")\n",
        "    conn.execute(\"SELECT InitSpatialMetaData(1);\")\n",
        "    conn.execute(\"\"\"SELECT ID FROM question_table ORDER BY ID\"\"\")\n",
        "    conn.execute(\"\"\"DROP TABLE IF EXISTS question_table_tmp \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Get all the questions\n",
        "query=\"\"\"SELECT ID, TYPE FROM question_table\"\"\" #if you want to get the total score too then you can add the column SCORE there\n",
        "\n",
        "with sqlite3.connect(DB_PATH) as conn: \n",
        "    idsScoresTypes = pd.read_sql(query, conn)\n",
        "\n",
        "\n",
        "#create dataframe holding the sum of all the scores\n",
        "sumDF = pd.DataFrame(idsScoresTypes)\n",
        "\n",
        "sumDF = sumDF.groupby(['ID', \"TYPE\"]).sum()\n",
        "\n",
        "sumDF.reset_index(inplace=True)\n",
        "\n",
        "sumDF[\"ID\"].astype(int)\n",
        "\n",
        "sumDF[\"completed\"] = \"no\"\n",
        "sumDF.rename(columns = {'ID':'id', \"TYPE\":\"type\"}, inplace = True)\n",
        "sumDF['type'] = sumDF['type'].apply(str.lower)\n",
        "\n",
        "#If the database already exists then I have to update it, otherwise just create a new one.\n",
        "if(databaseAlreadyExists):\n",
        "    #If all the questions about a way or node have 5 validations then they are completed, else set completed to false.\n",
        "    query = \"\"\"SELECT ID FROM question_table WHERE ID IN (select ID from question_table group by ID having NUMBEROFVALIDATIONS=5)\"\"\"\n",
        "    with sqlite3.connect(DB_PATH) as conn:\n",
        "        allCompletedDF = pd.read_sql(query, conn)\n",
        "    \n",
        "    allCompletedDF[\"completed\"] = \"yes\"\n",
        "    allCompletedDF.rename(columns = {'ID':'id'}, inplace = True)\n",
        "    sumDF.loc[sumDF['id'].isin(allCompletedDF['id']), 'completed'] = allCompletedDF['completed']\n",
        "\n",
        "    with sqlite3.connect(DB_PATH) as conn:\n",
        "        df_completed = sumDF.to_sql('completed_table',conn,if_exists=\"replace\", index = False)\n",
        "else:\n",
        "    with sqlite3.connect(DB_PATH) as conn:\n",
        "        df_completed = sumDF.to_sql('completed_table',conn,if_exists=\"replace\", index = False)\n",
        "#print(allCompletedDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''#Crete the table with the questions\n",
        "import pandas as pd\n",
        "\n",
        "for i in cityFilesOrder:\n",
        "    my_data = pd.read_csv(\"./tmp/allQuestions/\" + i + \"/wayQuestsNotSorted.csv\", index_col=False, delimiter='|')\n",
        "    my_data = my_data.rename(columns={'NODE OR WAY':'TYPE'})#########\n",
        "    my_data.drop(my_data.columns.difference(['TYPE','QUESTION','ID','SCORE','VALIDATING','ANSWERS','ICON', 'TAGANSWER']), 1, inplace=True)\n",
        "    my_data[\"ANSWER\"] = \"\"\n",
        "    my_data[\"USERANSWERED\"] = \"\"\n",
        "    my_data[\"NUMBEROFVALIDATIONS\"] = 0\n",
        "    my_data[\"USERSWHOVALIDATED\"] = \"\"\n",
        "    print(my_data.head())\n",
        "\n",
        "    with sqlite3.connect(DB_PATH) as conn: \n",
        "        df_sql = my_data.to_sql('question_table', conn, if_exists='append', index = False)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''#Take all the points of ways and nodes and sum the ones that have the same id. Put the value in the completed_table\n",
        "def getAllScores(i):\n",
        "    previousId = \"\"\n",
        "    allScores = []\n",
        "    currentId = \"\"\n",
        "    fileName = \"tmp/allQuestions/\" + i + \"/wayQuests.csv\"\n",
        "    with open(fileName) as csv_file:\n",
        "        csv_reader = csv.reader(csv_file, delimiter='|')\n",
        "        line_count = 0\n",
        "        for row in csv_reader:\n",
        "            if line_count == 0:\n",
        "                previousId = row[2]\n",
        "                currentId = row[2]\n",
        "                score = row[8]\n",
        "                element = {\n",
        "                    \"id\": currentId,\n",
        "                    \"score\": score\n",
        "                }\n",
        "                allScores.append(element);\n",
        "                line_count=line_count+1\n",
        "            else:\n",
        "                currentId = row[2]\n",
        "                score = row[8]\n",
        "                if(currentId==previousId):\n",
        "                    #modify existing element in list, do not append\n",
        "                    previousScore = allScores[len(allScores)-1]['score'];\n",
        "                    newScore = float(score) + float(previousScore)\n",
        "                    score_to_write = str(newScore)\n",
        "                    allScores[len(allScores)-1]['score'] = score_to_write\n",
        "                    line_count = line_count+1;\n",
        "                else:\n",
        "                    #append element with score\n",
        "                    score = row[8]\n",
        "                    previousId = currentId\n",
        "                    element = {\n",
        "                        \"id\": currentId,\n",
        "                        \"score\": score\n",
        "                    }\n",
        "                    allScores.append(element)\n",
        "                    line_count = line_count+1;\n",
        "\n",
        "    print(f'Processed {line_count} lines.')\n",
        "\n",
        "    point_df = pd.DataFrame(allScores);\n",
        "    return point_df'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''#Create the table to check whether or not the id has all the answer\n",
        "j=0\n",
        "for i in cityFilesOrder:\n",
        "    point_df = getAllScores(i)\n",
        "    completed_data = tutto[j]\n",
        "    #print(tutto[j])\n",
        "    completed_data = completed_data.drop(['shape'], axis = 1)\n",
        "    completed_data[\"completed\"] = \"no\"\n",
        "\n",
        "    completed_node = node_all[j]\n",
        "    completed_node = completed_node.drop(['shape'], axis=1)\n",
        "    completed_node[\"completed\"] = \"no\"\n",
        "    #print(completed_node.head())\n",
        "    #print(completed_data.head())\n",
        "    completed_node.append(completed_data)\n",
        "    #print(type(completed_data))\n",
        "    completed_data = gpd.GeoDataFrame( pd.concat( [completed_node,completed_data]) )\n",
        "    #print(len(completed_node))\n",
        "    #print(len(completed_data))\n",
        "    print(completed_data.head())\n",
        "    point_df[\"id\"]=point_df[\"id\"].astype(int)\n",
        "    completed_data = pd.merge(completed_data,point_df, on=\"id\")\n",
        "    with sqlite3.connect(DB_PATH) as conn:\n",
        "        df_completed = completed_data.to_sql('completed_table',conn,if_exists=\"append\", index = False)\n",
        "    j=j+1'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.enable_load_extension(True)\n",
        "    conn.load_extension(\"mod_spatialite\")\n",
        "    conn.execute(\"SELECT InitSpatialMetaData(1);\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DA QUA IN POI è COM'ERA UN TEMPO PER USARE TUTTO ASSIEME A QGIS E POTER QUINDI VISUALIZZARE LA MAPPA ASSIEME A TUTTI I DATI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''#creo la tabella senza però mettere la proprietà della geometria.\n",
        "df_way = tutto.drop(['shape'], axis = 1)\n",
        "df_nodes = node_all.drop(['shape'], axis = 1)\n",
        "with sqlite3.connect(DB_PATH) as conn: \n",
        "    df_way.to_sql('my_table_name', conn, if_exists='replace', index = False)\n",
        "    df_nodes.to_sql('my_node_table', conn, if_exists='replace', index = False)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''!pip install sqlalchemy'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''def init_dictionary(file_name, file_path, dict_list):\n",
        "    for i in file_name:\n",
        "        question = \"\"\n",
        "        #print(ways_questions_path + \"/\" + i)\n",
        "        with open(file_path + \"/\" + i) as f:\n",
        "            csv_reader = csv.reader(f, delimiter = '|')\n",
        "            lines = list(csv_reader)\n",
        "            for row in lines:\n",
        "                question = question + str(row[1]) + \"|\"\n",
        "        question = question[:-1]\n",
        "        #print(question + i)\n",
        "        id = i\n",
        "        id_split = id.split(\".\",1)\n",
        "        sub_id = id_split[0]\n",
        "        my_dict ={\n",
        "            \"id\" : sub_id,\n",
        "            \"question\" : question\n",
        "        }\n",
        "        dict_list.append(my_dict)\n",
        "    return dict_list'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''import geopandas\n",
        "import pandas as pd\n",
        "# shapely method to convert geometry objects into their well-known-binary representation\n",
        "import shapely.wkb\n",
        "# sqlite/spatialite\n",
        "from sqlalchemy import create_engine, event\n",
        "from sqlite3 import dbapi2 as sqlite\n",
        "#file operations\n",
        "import os\n",
        "\n",
        "nodes_questions_path = \"tmp/nodes_question\"\n",
        "ways_questions_path = \"tmp/ways_question\"\n",
        "ways_files = os.listdir(ways_questions_path)\n",
        "nodes_files = os.listdir(nodes_questions_path)\n",
        "dict_list = []\n",
        "node_dict_list = []\n",
        "dict_list = init_dictionary(ways_files, ways_questions_path, dict_list)\n",
        "node_dict_list = init_dictionary(nodes_files, nodes_questions_path, node_dict_list)\n",
        "\n",
        "#https://blog.softhints.com/python-create-table-mysql-from-dictionary/\n",
        "###https://gis.stackexchange.com/questions/141818/insert-geopandas-geodataframe-into-spatialite-database\n",
        "\n",
        "one_way_shapefile = tutto\n",
        "one_way_shapefile = geopandas.GeoDataFrame(one_way_shapefile, geometry='shape')\n",
        "one_way_shapefile.to_file('MyGeometries.shp', driver='ESRI Shapefile')\n",
        "gdf = geopandas.GeoDataFrame.from_file('MyGeometries.shp')\n",
        "gdf= gdf.astype({\"id\": str}, errors='raise') \n",
        "file = \"/MyGeometries.shp\"\n",
        "one_node_shapefile = node_all\n",
        "one_node_shapefile = geopandas.GeoDataFrame(one_node_shapefile, geometry='shape')\n",
        "one_node_shapefile.to_file('MyNodeGeometries.shp', driver='ESRI Shapefile')\n",
        "node_gdf = geopandas.GeoDataFrame.from_file('MyNodeGeometries.shp')\n",
        "node_gdf= node_gdf.astype({\"id\": str}, errors='raise') \n",
        "file = \"/MyNodeGeometries.shp\"\n",
        "\n",
        "\n",
        "gdf['geometry'] = gdf.apply(lambda x: shapely.wkb.dumps(x.geometry), axis=1)\n",
        "node_gdf['geometry'] = node_gdf.apply(lambda x: shapely.wkb.dumps(x.geometry), axis=1)\n",
        "print('writing into database...')\n",
        "\n",
        "with sqlite3.connect(DB_PATH) as conn: \n",
        "    gdf.to_sql('my_table_name', conn, if_exists='replace', index = False)\n",
        "    node_gdf.to_sql('my_node_table', conn, if_exists='replace', index = False)\n",
        "\n",
        "dict_df = pd.DataFrame.from_dict(dict_list)\n",
        "node_dict_df = pd.DataFrame.from_dict(node_dict_list)\n",
        "#dict_df = dict_df.astype({\"id\": str}, errors='raise') \n",
        "\n",
        "with sqlite3.connect(DB_PATH) as conn: \n",
        "    dict_df.to_sql('my_question_table', conn, if_exists='replace', index = False)\n",
        "    node_dict_df.to_sql('my_node_question_table', conn, if_exists='replace', index = False)\n",
        "#ELIMINO GLI ID CHE NON SONO PRESENTI DELLA TABELLA MY_TABLE_NAME\n",
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.enable_load_extension(True)\n",
        "    conn.load_extension(\"mod_spatialite\")\n",
        "    conn.execute(\"SELECT InitSpatialMetaData(1);\")\n",
        "    conn.execute(\"\"\"DELETE \n",
        "                    FROM my_question_table\n",
        "                    WHERE  ID NOT IN (SELECT id\n",
        "                                FROM   my_table_name)\"\"\")\n",
        "    conn.execute(\"\"\"DELETE \n",
        "                    FROM my_node_question_table\n",
        "                    WHERE  ID NOT IN (SELECT id\n",
        "                                FROM   my_node_table)\"\"\")\n",
        "\n",
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.enable_load_extension(True)\n",
        "    conn.load_extension(\"mod_spatialite\")\n",
        "    conn.execute(\"SELECT InitSpatialMetaData(1);\")\n",
        "    conn.execute(\"\"\"SELECT * FROM 'my_table_name' NATURAL JOIN 'my_question_table'\"\"\")\n",
        "    conn.execute(\"\"\"SELECT * FROM 'my_node_table' NATURAL JOIN 'my_node_question_table'\"\"\")\n",
        "    conn.commit()\n",
        "\n",
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.enable_load_extension(True)\n",
        "    conn.load_extension(\"mod_spatialite\")\n",
        "    conn.execute(\"SELECT InitSpatialMetaData(1);\")\n",
        "    conn.execute(\"\"\"DROP TABLE IF EXISTS merged\"\"\")\n",
        "    conn.execute(\"\"\"DROP TABLE IF EXISTS node_merged\"\"\")\n",
        "\n",
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.enable_load_extension(True)\n",
        "    conn.load_extension(\"mod_spatialite\")\n",
        "    conn.execute(\"SELECT InitSpatialMetaData(1);\")\n",
        "    conn.execute(\"\"\"CREATE TABLE merged AS\n",
        "                    SELECT * FROM \"my_table_name\"\n",
        "                    NATURAL JOIN\n",
        "                    'my_question_table'\"\"\")\n",
        "    conn.execute(\"\"\"CREATE TABLE node_merged AS\n",
        "                    SELECT * FROM \"my_node_table\"\n",
        "                    NATURAL JOIN\n",
        "                    'my_node_question_table'\"\"\")\n",
        "\n",
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.enable_load_extension(True)\n",
        "    conn.load_extension(\"mod_spatialite\")\n",
        "    conn.execute(\"SELECT InitSpatialMetaData(1);\")\n",
        "    conn.execute(\n",
        "        \"\"\"SELECT AddGeometryColumn('merged', 'geom', 4326, 'LINESTRING', 2);\"\"\"\n",
        "    )\n",
        "    conn.execute(\n",
        "        \"\"\"SELECT AddGeometryColumn('node_merged', 'geom', 4326, 'POINT', 2);\"\"\"\n",
        "    )\n",
        "\n",
        "    conn.commit()\n",
        "\n",
        "print(\"AFTER TABLE NAME\")\n",
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.enable_load_extension(True)\n",
        "    conn.load_extension(\"mod_spatialite\")\n",
        "    conn.execute(\"UPDATE merged SET geom=GeomFromWKB(geometry, 4326);\")\n",
        "    conn.execute(\"UPDATE node_merged SET geom=GeomFromWKB(geometry, 4326);\")\n",
        "    conn.commit()\n",
        "    \n",
        "#engine.execute(\"SELECT AddGeometryColumn('my_table_name', 'geom', 4326, 'LINE', 2);\")\n",
        "\n",
        "#engine.execute(\"UPDATE my_table_name SET geom=GeomFromWKB(geometry, 4326);\")\n",
        "print(\"AFTER TABLE NAME\")\n",
        "#https://gis.stackexchange.com/questions/137149/how-to-delete-a-column-from-the-attribute-table-of-a-spatialite-layer\n",
        "#connection = engine.connect()\n",
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.execute(\"\"\"BEGIN TRANSACTION\"\"\")\n",
        "    conn.execute(\"\"\"CREATE TEMPORARY TABLE t1_backup(id,type,question,geom)\"\"\")\n",
        "    conn.execute(\"\"\"INSERT INTO t1_backup SELECT id,type,question,geom FROM merged\"\"\")\n",
        "    conn.execute(\"\"\"DROP TABLE merged\"\"\")\n",
        "    conn.execute(\"\"\"CREATE TABLE merged(id,type,question,geom)\"\"\")\n",
        "    conn.execute(\"\"\"INSERT INTO merged SELECT id,type,question,geom FROM t1_backup\"\"\")\n",
        "    conn.execute(\"\"\"DROP TABLE t1_backup\"\"\")\n",
        "    conn.commit();\n",
        "\n",
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.execute(\"\"\"BEGIN TRANSACTION\"\"\")\n",
        "    conn.execute(\"\"\"CREATE TEMPORARY TABLE tnode_backup(id,type,question,geom)\"\"\")\n",
        "    conn.execute(\"\"\"INSERT INTO tnode_backup SELECT id,type,question,geom FROM node_merged\"\"\")\n",
        "    conn.execute(\"\"\"DROP TABLE node_merged\"\"\")\n",
        "    conn.execute(\"\"\"CREATE TABLE node_merged(id,type,question,geom)\"\"\")\n",
        "    conn.execute(\"\"\"INSERT INTO node_merged SELECT id,type,question,geom FROM tnode_backup\"\"\")\n",
        "    conn.execute(\"\"\"DROP TABLE tnode_backup\"\"\")\n",
        "    conn.commit();\n",
        "# start functions\n",
        "#writeIntoDatabase()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''#NOW I DROP THE TABLES THAT I DO NOT NEED ANYMORE\n",
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.execute(\"\"\"DROP TABLE IF EXISTS my_question_table \"\"\")\n",
        "    conn.execute(\"\"\"DROP TABLE IF EXISTS my_node_table \"\"\")\n",
        "    conn.execute(\"\"\"DROP TABLE IF EXISTS my_table_name \"\"\")\n",
        "    conn.execute(\"\"\"DROP TABLE IF EXISTS my_node_question_table\"\"\")\n",
        "    conn.execute(\"\"\"DROP TABLE IF EXISTS my_node_question_table\"\"\")\n",
        "    conn.commit();\n",
        "    #my_node_table\n",
        "    #my_table_name'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''#MOSTRA TUTTI GLI ID DELLE STRADE DISTANTI TOT METRI DAL MIO PUNTO\n",
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.enable_load_extension(True)\n",
        "    conn.load_extension(\"mod_spatialite\")\n",
        "    cur = conn.execute(\n",
        "        \"\"\"SELECT id from node_merged where ST_Distance(GeomFromText('POINT(11.194239 46.052415)',4326),geom,0)< 2500.120;\"\"\"\n",
        "    )\n",
        "    results = cur.fetchall()\n",
        "print(results)\n",
        "conn.close()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''#MOSTRA DISTANZA DA UN DATO PUNTO DI TUTTI I MIEI ELEMENTI\n",
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.enable_load_extension(True)\n",
        "    conn.load_extension(\"mod_spatialite\")\n",
        "    cur = conn.execute(\n",
        "        \"\"\"select ST_Distance(GeomFromText('POINT(11.194239 46.052415)',4326),geom) from merged;\"\"\"\n",
        "    )\n",
        "    results = cur.fetchall()\n",
        "print(results)\n",
        "conn.close()\n",
        "\n",
        "\n",
        "\n",
        "#11.19314879999986,46.05232919995909\n",
        "#11.19536759999801,46.05260819995721'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''#with open(\"/tmp/myjsonfile.geojson\",\"w\") as f:\n",
        "#  json.dump(my_object, f);\n",
        "\n",
        "#lo 0 sta per \"usa ellissi\" https://www.gaia-gis.it/gaia-sins/spatialite-sql-4.3.0.html\n",
        "with sqlite3.connect(DB_PATH) as conn:\n",
        "    conn.enable_load_extension(True)\n",
        "    conn.load_extension(\"mod_spatialite\")\n",
        "    cur = conn.execute(\n",
        "        \"\"\"SELECT id, AsText(geom) from merged where ST_Distance(GeomFromText('POINT(11.194239 46.052415)',4326),geom,0)< 111.120;\"\"\"\n",
        "    )\n",
        "    results = cur.fetchall()\n",
        "print(results)\n",
        "conn.close()\n",
        "\n",
        "#il valore dopo il < è già espresso in metri\n",
        "\n",
        "\n",
        "the unit returned by ST_Distance(), ST_Length() and ST_Area() exactly is the one defined by the corresponding SRID.\n",
        "consequently, if you are using latitude and longitude (SRID=4326, WGS 84), any length will be measured in DEGREES, and any area in SQUARE DEGREES.\n",
        "degree latitude is exactly 60 nautical miles apart. That's 111,120 meters or 364,567 feet. Just multiply the value from Distance() with 111,120 to get the distance in meters.\n",
        "\n",
        "\n",
        "\n",
        "#select id, AsText(geom) from my_table_name where ST_Distance(GeomFromText('POINT(11.130962 46.012215)',4326),geom,0)< 20000.0;'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYQ_NyL0Jz_d"
      },
      "outputs": [],
      "source": [
        "#https://gis.stackexchange.com/questions/353082/plotting-shapely-multipolygon-using-matplotlib\n",
        "\n",
        "#fig, axs = plt.subplots()\n",
        "#fig, ax = plt.subplots(figsize=(12,12))\n",
        "#fig.set_size_inches(12, 12, forward=True)\n",
        "#axs.set_aspect('equal', 'datalim')\n",
        "\n",
        "#for geom in trento:    \n",
        "#    xs, ys = geom.exterior.xy    \n",
        "#    axs.fill(xs, ys, alpha=0.5, fc='r', ec='none')\n",
        "\n",
        "#plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FBKIterateQuestions.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}